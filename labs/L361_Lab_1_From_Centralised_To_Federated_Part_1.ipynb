{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTR0VzOm2B5d"
   },
   "source": [
    "# 0. Marking.\n",
    "\n",
    "***IMPORTANT***: Save a copy of this notebook into your Drive before you start.\n",
    "- Please attempt all the questions marked for your group (Part II ✅ | Part III/MPhil ✅).\n",
    "- Continue to part 2 after you are done with this one.\n",
    "\n",
    "Please submit a zip file, containing both parts, consiting of of:\n",
    "1. A text file with a publicly visible link to your notebooks in Google Colab or GitHub.\n",
    "2. A downloaded copy (ipynb) of your notebooks or your zipped cloned GitHub repo. You may treat these as a report: we will not be re-executing the code you used to produce the answers unless required.\n",
    "\n",
    "If you find yourself enjoying the material, feel free to attempt more! Provide your answers in a new cell below the question cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0eSNvNJFrjt"
   },
   "source": [
    "### 1. Introduction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMqp_FvE2B5f"
   },
   "source": [
    "Welcome to the first lab in our Federated Learning (FL) course. This series of labs intends to introduce you to the practice of constructing Federated Learning systems. The most common form of FL, cross-device FL, is concerned with collaboratively training models on edge devices or “clients'' encapsulating their private data. As such, FL may:\n",
    "- Reduce communication costs by only sharing model parameters.\n",
    "- Distribute computation across a pool of previously unused devices.\n",
    "- Partially preserve privacy by default.\n",
    "\n",
    "A typical server-client FL system maintains a centralised server that synchronises training across iterations of rounds---the FL equivalent of epochs. A round generally proceeds as follows:\n",
    "1. At the beginning of a round, the server sends a copy of the federated model to each client.\n",
    "2. The clients then train their copy of the model on the private data they hold and send the post-training model updates to the server.\n",
    "3. The server then aggregates all the client models to form a single federated model update which it applies before the next round. The most common means of aggregation is Federated Averaging which merges model parameters via simple weighted averaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhnE5-YklGrK"
   },
   "source": [
    "\n",
    "![picture](https://drive.google.com/uc?id=1QhUB6Eb-P1hf0LCKWp5f6rEeGThLCmbE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvDvRvsvN80X"
   },
   "source": [
    "To a more significant extent than other ML fields, FL has historically been driven by practical considerations rather than theoretical results. Some main practical concerns in the field are related to the following:\n",
    "- Communication costs involved in training models in a highly distributed fashion across edge devices.\n",
    "- The underlying non-standardized hardware of clients within the federated network.\n",
    "- Highly divergent data distributions across clients.\n",
    "\n",
    "Such issues cannot be easily corrected, given FL's privacy and scale constraints, as persistent data on specific clients may not be trackable. In a worst-case setting, a single client may only participate in training once for cross-device FL with millions of potential devices.\n",
    "\n",
    "In this lab, we will use a realistic FL dataset to exemplify how such problems arise when ML is taken from a centralized or standard distributed ML setting to a federated one. Specific questions we will look at include the following:\n",
    "- How centralized ML can be modeled as FL with a single client and how to build a client abstraction capable of both.\n",
    "- How the federated and local optimization objectives of FL interact between each other and how different settings on the server/client side may impact convergence.\n",
    "\n",
    "To do so, we shall use the [Flower](https://flower.dev/) FL framework. The design of Flower is meant to allow for a fairly direct mapping between simulation and production FL scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zeAdW4nnSv5"
   },
   "source": [
    "\n",
    "![picture](https://drive.google.com/uc?id=19MZ2nHIgLTZEqgSgbP9z9BKVyiR8GT3X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m45tcB_gL0pw"
   },
   "source": [
    "# 2. Building a client.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvxdivaBODPZ"
   },
   "source": [
    "Rather than beginning with a complete standard centralised ML baseline, we will treat centralised ML as a particular case of FL--a single client holding the entire centralised dataset.\n",
    "\n",
    "For the rest of our labs, a client shall represent an abstraction that:\n",
    "- Encapsulates the data available on a particular device involved in FL.\n",
    "- Trains a model it receives on that local (train) dataset.\n",
    "- Can test models it receives on its local (test) dataset.\n",
    "\n",
    "By the end of this section, you will have constructed such a client abstraction and trained a model on a full-scale dataset. Later work shall merely involve connecting multiple such clients in a federated network using Flower.\n",
    "\n",
    "To begin, we will need to install some dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:40.438344Z",
     "iopub.status.busy": "2024-02-02T18:50:40.437869Z",
     "iopub.status.idle": "2024-02-02T18:50:50.601988Z",
     "shell.execute_reply": "2024-02-02T18:50:50.601074Z",
     "shell.execute_reply.started": "2024-02-02T18:50:40.438309Z"
    },
    "id": "XenFLb3FMF0s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    }
   ],
   "source": [
    "# The simulation component of the flower framework uses RAY under the hood.\n",
    "# `pip` could produce some errors. Do not worry about them.\n",
    "# The execution has been verified; it's working anyway.\n",
    "! pip install --quiet --upgrade \"pip\"\n",
    "! pip install --quiet git+https://github.com/Iacob-Alexandru-Andrei/flower.git@teaching torch torchvision matplotlib gdown tqdm seaborn ray==\"2.6.3\"\n",
    "# The following is just needed to show the folder tree\n",
    "! apt-get install -qq tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiW6ObflQhSi"
   },
   "source": [
    "Our first client abstraction shall be as simple as possible and will require adjustment to match the structure that the framework expects. However, it shall be conceptually identical and require only light API changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:50.603643Z",
     "iopub.status.busy": "2024-02-02T18:50:50.603364Z",
     "iopub.status.idle": "2024-02-02T18:50:53.130310Z",
     "shell.execute_reply": "2024-02-02T18:50:53.128809Z",
     "shell.execute_reply.started": "2024-02-02T18:50:50.603616Z"
    },
    "id": "eO7LWfu4RL7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xt0r3-user/anaconda3/envs/fl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-02-02 18:50:50,925\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "\n",
    "import csv\n",
    "import numbers\n",
    "import os\n",
    "import random\n",
    "from collections import OrderedDict, defaultdict\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "\n",
    "import flwr as fl\n",
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from flwr.common import Metrics\n",
    "from flwr.common.parameter import ndarrays_to_parameters\n",
    "from flwr.common.typing import NDArrays, Parameters, Scalar\n",
    "from flwr.server import ServerConfig\n",
    "from flwr.server.strategy import FedAvgM as FedAvg\n",
    "from PIL import Image\n",
    "from PIL.Image import Image as ImageType\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from enum import IntEnum\n",
    "\n",
    "\n",
    "# Add new seeds here for easy autocomplete\n",
    "class Seeds(IntEnum):\n",
    "    DEFAULT = 1337\n",
    "\n",
    "\n",
    "np.random.seed(Seeds.DEFAULT)\n",
    "random.seed(Seeds.DEFAULT)\n",
    "torch.manual_seed(Seeds.DEFAULT)\n",
    "torch.backends.cudnn.benchmark = False  # type: ignore\n",
    "torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "\n",
    "\n",
    "def convert(o):\n",
    "    if isinstance(o, np.int64) or isinstance(o, np.int32):\n",
    "        return int(o)\n",
    "    if isinstance(o, np.float32) or isinstance(o, np.float64):\n",
    "        return float(o)\n",
    "    raise TypeError\n",
    "\n",
    "\n",
    "def fit_client_seeded(client, params, conf, seed=Seeds.DEFAULT, **kwargs):\n",
    "    \"\"\"Wrapper to always seed client training.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    return client.fit(params, conf, **kwargs)\n",
    "\n",
    "\n",
    "PathType = Optional[Union[Path, str]]\n",
    "\n",
    "\n",
    "def get_device() -> str:\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        device = \"mps\"\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:53.132060Z",
     "iopub.status.busy": "2024-02-02T18:50:53.131690Z",
     "iopub.status.idle": "2024-02-02T18:50:53.140531Z",
     "shell.execute_reply": "2024-02-02T18:50:53.140067Z",
     "shell.execute_reply.started": "2024-02-02T18:50:53.132038Z"
    },
    "id": "fa-jqHRaQ1C2"
   },
   "outputs": [],
   "source": [
    "class SimpleClient:\n",
    "    def __init__(self, cid: int, partition_dir: Path) -> None:\n",
    "        \"\"\"Function to initialise the client with its unique id\n",
    "        and the directory from which it can load its data.\n",
    "\n",
    "        Args:\n",
    "            cid (int): Unique client id for a client used to map it to its data partition\n",
    "            partition_dir (Path): The directory containing data for each client/client id\n",
    "        \"\"\"\n",
    "        self.cid: str = str(cid)\n",
    "        self.partition_dir: Path = partition_dir\n",
    "        self.device: str = get_device()\n",
    "\n",
    "    def fit(self, net: Module, config: Dict[str, Any]) -> Tuple[Module, int, dict]:\n",
    "        \"\"\"Function which receives and trains a model on the local client data using parameters from the config dict\n",
    "\n",
    "        Args:\n",
    "            net (Module): Pytorch model\n",
    "            config (Dict[str, Any]): Dictionary describing the training parameters\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Module, int, dict]: Returns the updated model, the size of the local dataset and (optionally) other metrics\n",
    "        \"\"\"\n",
    "        net = deepcopy(net)\n",
    "        net.to(self.device)\n",
    "        train_loader: DataLoader = self._create_data_loader(config, name=\"train\")\n",
    "        self._train(net, train_loader=train_loader, config=config)\n",
    "        return net, len(train_loader), {}\n",
    "\n",
    "    def evaluate(self, net: Module, config: Dict[str, Any]) -> Tuple[float, int, dict]:\n",
    "        \"\"\"Function which receives and tests a model on the local client data using parameters from the config dict\n",
    "\n",
    "        Args:\n",
    "            net (Module): Pytorch model\n",
    "            config (Dict[str, Any]): Dictionary describing the test parameters\n",
    "\n",
    "        Returns:\n",
    "            Tuple[float, int, dict]: Returns the loss accumulate during test, the size of the local dataset and other metrics such as accuracy\n",
    "        \"\"\"\n",
    "        net = deepcopy(net)\n",
    "        net.to(self.device)\n",
    "        test_loader: DataLoader = self._create_data_loader(config, name=\"test\")\n",
    "        loss, accuracy = self._test(net, test_loader=test_loader, config=config)\n",
    "        return loss, len(test_loader), {\"local_accuracy\": accuracy}\n",
    "\n",
    "    def _create_data_loader(self, config: Dict[str, Any], name: str) -> DataLoader:\n",
    "        \"\"\"Creates the data loader using the specified config parameters\n",
    "\n",
    "        Args:\n",
    "            config (Dict[str, any]): Dictionary containing dataloader and dataset parameters\n",
    "            name (str): Load the training or testing set for the client\n",
    "\n",
    "        Returns:\n",
    "            DataLoader: A pytorch dataloader iterable for training/testing\n",
    "        \"\"\"\n",
    "        batch_size: int = config[\"batch_size\"]\n",
    "        num_workers: int = config[\"num_workers\"]\n",
    "        dataset = self._load_dataset(name, config)\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=False if name == \"test\" else True,\n",
    "        )\n",
    "\n",
    "    # All methods from here on are task-specific\n",
    "    # And need to be implemented\n",
    "    def _load_dataset(self, name: str, config: Dict[str, Any]) -> Dataset:  # type: ignore\n",
    "        pass\n",
    "\n",
    "    def _train(\n",
    "        self, net: Module, train_loader: DataLoader, config: Dict[str, Any]\n",
    "    ) -> float:  # type: ignore\n",
    "        pass\n",
    "\n",
    "    def _test(\n",
    "        self, net, test_loader: DataLoader, config: Dict[str, Any]\n",
    "    ) -> Tuple[float, float]:  # type: ignore\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfcgBtrhVtAo"
   },
   "source": [
    "This client covers all the previously stated functionality; it can:\n",
    "- Associate a given dataset/dataset partition to itself based on the `data_dir` and `cid` combination\n",
    "- Train any model provided to its `fit` function on the local training set\n",
    "- Evaluate any model on the local test set.\n",
    "\n",
    "To get this client training, we need to fill in the necessary gaps: the dataset loading procedure, the model, the training procedure and the testing procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPf2tk1P2B5l"
   },
   "source": [
    "**Question 1 (Part II ✅ | Part III/MPhil ✅):**\n",
    "\n",
    "(These are meant to be conceptual questions. You should provide written answers for these. **No more than 3 sentences each**. **No code** is needed)\n",
    "\n",
    "1. What is the time complexity of transmitting models to-and-from the client?\n",
    "    - $O(sz)$, where $sz$ is the size of the model, as we create a deep copy of all the parameters.\n",
    "2. Give at least two examples of machine learning and data science techniques you cannot apply since data is kept private on single clients.\n",
    "    - Cross validation with stratification is impossible, since we can't estimate the global number of labels in each class.\n",
    "    - We can't do an uniform evaluation of how well each of the local models are doing because we don't have the same data over all the models. This makes it so that even if we choose the perfect metric to optimise during training, we still can't be sure that the model is learning the right thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zocsNC84Wk_l"
   },
   "source": [
    "# 3. Loading the federated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NhUGGSrfkrJ"
   },
   "source": [
    "We have chosen to use the FEMNIST dataset originally published in [LEAF](https://arxiv.org/abs/1812.01097) for all of our labs due to its naturally heterogeneous properties. Most FL examples rely on a centralised dataset such as CIFAR-10, which is artificially partitioned to fit an FL context. FEMNIST is an image dataset with 28×28 greyscale images split into 62 distinct classes. We shall initially treat it as a centralised dataset. However, its federated nature will be helpful later on.\n",
    "\n",
    "It is, by default, partitioned based on the creator of a specific image, thus modelling a realistic data-generation scenario. A complete list of its statistics may be found on the [LEAF Website](https://leaf.cmu.edu/).\n",
    "\n",
    "We will extensively discuss federated datasets during the next lab. In this session, we will skip such discussions to spend more time on “federating” a centralised model. The following few cells will provide all the relevant functions and objects to load the FEMNIST dataset. Also, some **optional** insights will be given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:53.142325Z",
     "iopub.status.busy": "2024-02-02T18:50:53.142047Z",
     "iopub.status.idle": "2024-02-02T18:50:53.149441Z",
     "shell.execute_reply": "2024-02-02T18:50:53.148491Z",
     "shell.execute_reply.started": "2024-02-02T18:50:53.142304Z"
    },
    "id": "xDpybqNURmr6"
   },
   "outputs": [],
   "source": [
    "home_dir = content if (content := Path(\"/content\")).exists() else Path.cwd()\n",
    "dataset_dir: Path = home_dir / \"femnist\"\n",
    "data_dir: Path = dataset_dir / \"data\"\n",
    "centralized_partition: Path = dataset_dir / \"client_data_mappings\" / \"centralized\"\n",
    "centralized_mapping: Path = dataset_dir / \"client_data_mappings\" / \"centralized\" / \"0\"\n",
    "federated_partition: Path = dataset_dir / \"client_data_mappings\" / \"fed_natural\"\n",
    "\n",
    "#  Download compressed dataset\n",
    "if not (home_dir / \"femnist.tar.gz\").exists():\n",
    "    id = \"1-CI6-QoEmGiInV23-n_l6Yd8QGWerw8-\"\n",
    "    gdown.download(\n",
    "        f\"https://drive.google.com/uc?export=download&confirm=pbef&id={id}\",\n",
    "        str(home_dir / \"femnist.tar.gz\"),\n",
    "    )\n",
    "\n",
    "# Decompress dataset\n",
    "if not dataset_dir.exists():\n",
    "    !tar -xf {str(home_dir)}/femnist.tar.gz -C {str(home_dir)} 2> /dev/null\n",
    "    print(f\"Dataset extracted in {dataset_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiMa5eYORmr6"
   },
   "source": [
    "You can **optionally** execute the following cell to look at the folder tree induced by unzipping the compressed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:53.151263Z",
     "iopub.status.busy": "2024-02-02T18:50:53.150770Z",
     "iopub.status.idle": "2024-02-02T18:50:53.276724Z",
     "shell.execute_reply": "2024-02-02T18:50:53.275861Z",
     "shell.execute_reply.started": "2024-02-02T18:50:53.151215Z"
    },
    "id": "FR92a5uyRmr6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m./\u001b[00m\n",
      "├── \u001b[01;34mcommon\u001b[00m\n",
      "│   └── \u001b[01;34m__pycache__\u001b[00m\n",
      "├── \u001b[01;34mfemnist\u001b[00m\n",
      "│   ├── \u001b[01;34mclient_data_mappings\u001b[00m\n",
      "│   │   ├── \u001b[01;34mcentralized\u001b[00m\n",
      "│   │   └── \u001b[01;34mfed_natural\u001b[00m\n",
      "│   └── \u001b[01;34mdata\u001b[00m\n",
      "│       ├── \u001b[01;34mtest\u001b[00m\n",
      "│       ├── \u001b[01;34mtrain\u001b[00m\n",
      "│       └── \u001b[01;34mval\u001b[00m\n",
      "└── \u001b[01;34mhistories\u001b[00m\n",
      "\n",
      "11 directories\n"
     ]
    }
   ],
   "source": [
    "# Showing resulting folder tree\n",
    "! tree -dC -L 3 ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-70unJnRmr6"
   },
   "source": [
    "For those of you gifted with eager curiosity, you can find the [Jupyter notebook](https://drive.google.com/file/d/1-I0uPPzm1ONlLD-u4XCFGqUgz6KPJzDe/view?usp=share_link) used to create this dataset from the version publicly available from TensorFlow Federated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moqCXNdjRmr6"
   },
   "source": [
    "We have thus downloaded two different partitions of the FEMNIST dataset. We will first use the “centralised” partition, in which we have distributed all the samples to one client. The second is the “natural” partition, in which the images/samples have been divided by writers.\n",
    "\n",
    "Samples have been collected once in the `data` folder, composed of three subfolders- `train`, `test` and `val`-, each containing one file for each sample in those sets. Then, it is the `client_data_mappings` folder that contains the relevant structure, composed of subfolders and `.csv` files, each describing the partitions. In fact, for each client, a `train.csv` and a `test.csv` are provided, containing a row for each sample in the client set that reports `client_id`, `sample_path`, `sample_id`, `sample_label`. It is worth mentioning that while train and test sets have been composed of the same clients, the validation set has been composed of different clients. That is why the only `val.csv` contained in this folder structure is under the centralised partition.\n",
    "\n",
    "The number of clients composing the train and test sets is 3230, while the number of clients composing the `val` set is 170. The splitting has been chosen to make the validation step quick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muCGzjZ9qWoj"
   },
   "source": [
    "# 4. Centralized ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHmJIyUsWi7O"
   },
   "source": [
    "We will begin with our centralised “partition”. We then use the entire `train.csv` and `test.csv` contained in `client_data_mappings/centralized/0`. For a large section of FL tasks, the centralised baseline represents the upper limit of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:53.279063Z",
     "iopub.status.busy": "2024-02-02T18:50:53.278243Z",
     "iopub.status.idle": "2024-02-02T18:50:53.289077Z",
     "shell.execute_reply": "2024-02-02T18:50:53.288505Z",
     "shell.execute_reply.started": "2024-02-02T18:50:53.279034Z"
    },
    "id": "wgSy30y6n8hR"
   },
   "outputs": [],
   "source": [
    "class FEMNIST(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mapping: Path,\n",
    "        data_dir: Path = data_dir,\n",
    "        name: str = \"train\",\n",
    "        transform: Optional[Callable[[ImageType], Any]] = None,\n",
    "        target_transform: Optional[Callable[[int], Any]] = None,\n",
    "    ):\n",
    "        \"\"\"Function to initialise the FEMNIST dataset.\n",
    "\n",
    "        Args:\n",
    "            mapping (Path): path to the mapping folder containing the .csv files.\n",
    "            data_dir (Path): path to the dataset folder. Defaults to data_dir.\n",
    "            name (str): name of the dataset to load, train or test.\n",
    "            transform (Optional[Callable[[ImageType], Any]], optional): transform function to be applied to the ImageType object. Defaults to None.\n",
    "            target_transform (Optional[Callable[[int], Any]], optional): transform function to be applied to the label. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.mapping = mapping\n",
    "        self.name = name\n",
    "\n",
    "        self.data: Sequence[Tuple[str, int]] = self._load_dataset()\n",
    "        self.transform: Optional[Callable[[ImageType], Any]] = transform\n",
    "        self.target_transform: Optional[Callable[[int], Any]] = target_transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[Any, Any]:\n",
    "        \"\"\"Function used by PyTorch to get a sample.\n",
    "\n",
    "        Args:\n",
    "            index (_type_): index of the sample.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Any, Any]: couple (sample, label).\n",
    "        \"\"\"\n",
    "        sample_path, label = self.data[index]\n",
    "\n",
    "        # Convert to the full path\n",
    "        full_sample_path: Path = self.data_dir / self.name / sample_path\n",
    "\n",
    "        img: ImageType = Image.open(full_sample_path).convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Function used by PyTorch to get the length of the dataset as the number of samples.\n",
    "\n",
    "        Returns:\n",
    "            int: the length of the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def _load_dataset(self) -> Sequence[Tuple[str, int]]:\n",
    "        \"\"\"Load the paths and labels of the partition\n",
    "        Preprocess the dataset for faster future loading\n",
    "        If opened for the first time.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: raised if the mapping file does not exist.\n",
    "\n",
    "        Returns:\n",
    "            Sequence[Tuple[str, int]]: partition asked as a sequence of couples (path_to_file, label)\n",
    "        \"\"\"\n",
    "        preprocessed_path: Path = (self.mapping / self.name).with_suffix(\".pt\")\n",
    "        if preprocessed_path.exists():\n",
    "            return torch.load(preprocessed_path)\n",
    "        else:\n",
    "            csv_path = (self.mapping / self.name).with_suffix(\".csv\")\n",
    "            if not csv_path.exists():\n",
    "                raise ValueError(f\"Required files do not exist, path: {csv_path}\")\n",
    "            else:\n",
    "                with open(csv_path, mode=\"r\") as csv_file:\n",
    "                    csv_reader = csv.reader(csv_file)\n",
    "                    # Ignore header\n",
    "                    next(csv_reader)\n",
    "\n",
    "                    # Extract the samples and the labels\n",
    "                    partition: Sequence[Tuple[str, int]] = [\n",
    "                        (sample_path, int(label_id))\n",
    "                        for _, sample_path, _, label_id in csv_reader\n",
    "                    ]\n",
    "\n",
    "                    # Save for future loading\n",
    "                    torch.save(partition, preprocessed_path)\n",
    "                    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:53.290324Z",
     "iopub.status.busy": "2024-02-02T18:50:53.289985Z",
     "iopub.status.idle": "2024-02-02T18:50:53.625532Z",
     "shell.execute_reply": "2024-02-02T18:50:53.624847Z",
     "shell.execute_reply.started": "2024-02-02T18:50:53.290309Z"
    },
    "id": "_o3YKN3UpNmg"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APf6KKKK5LxV4vm0XUoNNtEsEnktpLtrjUbkwQoiEDAIBLMSeg6Dk10GkXsmo6NY301u1tLcW8crwMcmMsoJU/TOKu0VDPaW100bXFvFKYm3xmRA2xvUZ6GpqKKKKK//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmUlEQVR4AWP8z4AbMOGWYmAYRpIsKP7894+BCclzjMgh9J8RRSkDiiTDtR3MPspISv7Dwd9fqcw2wpr//8FFGOCs3//nsGz//1Dwxf+/MDFkSR+z//83mfyBy/1HSP75t4UvvERk4/8/MI3/EQ5n/u+95Y/oSb//zHAnI7v2H0glmIBKI0syoIUBmj/hBkIYCDvRJEDcYSQJALJrd6RY7PX/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset: FEMNIST = FEMNIST(mapping=centralized_mapping, data_dir=data_dir, name=\"train\")\n",
    "\n",
    "# Show random value\n",
    "img, _ = dataset[4]\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zp12GiFVaYXo"
   },
   "source": [
    "Given this fully “centralised” dataset, the client abstraction only requires functions implementing data loading, model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:53.626389Z",
     "iopub.status.busy": "2024-02-02T18:50:53.626236Z",
     "iopub.status.idle": "2024-02-02T18:50:53.630548Z",
     "shell.execute_reply": "2024-02-02T18:50:53.629830Z",
     "shell.execute_reply.started": "2024-02-02T18:50:53.626376Z"
    },
    "id": "URtFwYX0iNSR"
   },
   "outputs": [],
   "source": [
    "# Load with appropriate transforms\n",
    "def to_tensor_transform(p: Any) -> torch.Tensor:\n",
    "    \"\"\"Transform the object given to a PyTorch Tensor.\n",
    "\n",
    "    Args:\n",
    "        p (Any): object to transform.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: resulting PyTorch Tensor\n",
    "    \"\"\"\n",
    "    return torch.tensor(p)\n",
    "\n",
    "\n",
    "def load_FEMNIST_dataset(mapping: Path, name: str) -> Dataset:\n",
    "    \"\"\"Function to load the FEMNIST dataset given the mapping .csv file.\n",
    "    The relevant transforms are automatically applied.\n",
    "\n",
    "    Args:\n",
    "        mapping (Path): path to the mapping .csv file chosen.\n",
    "        name (str): name of the dataset to load, train or test.\n",
    "\n",
    "    Returns:\n",
    "        Dataset: FEMNIST dataset object, ready-to-use.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            # transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FEMNIST(\n",
    "        mapping=mapping,\n",
    "        name=name,\n",
    "        data_dir=data_dir,\n",
    "        transform=transform,\n",
    "        target_transform=to_tensor_transform,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnFffXP0FBUB"
   },
   "source": [
    "Partitions in FL datasets may vary in data-per-client by orders of magnitude. While in the “centralised” case, one client holds $O(N)$ samples with $N \\approx 80,5263$, a natural partitioning by image creator ID will result in each client holding $O(m)$ samples with $m \\approx 226$.\n",
    "\n",
    "This points to a more fundamental issue in FL, the unbalanced size of local datasets across clients. Several questions arise when considering the potential orders-of-magnitude gap between clients:\n",
    "1. How do we set the amount of training each client does per round?\n",
    "2. How should we balance the contribution of several clients, given differences in dataset size?\n",
    "\n",
    "The original paper introducing FL, [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/abs/1602.05629), and the Federated Averaging algorithm we shall use today answers the questions in the following ways:\n",
    "1. Set a number of local epochs homogenous across clients; each client iterates over their entire dataset for the provided number of epochs.\n",
    "2. When combining the models of different clients, weigh them by the size of the local dataset of the clients.\n",
    "\n",
    "For now, we shall choose to keep the local epoch design and place an absolute upper limit on the number of batches seen during training/testing due to the computational constraints of training the centralised client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:53.632612Z",
     "iopub.status.busy": "2024-02-02T18:50:53.632322Z",
     "iopub.status.idle": "2024-02-02T18:50:53.635258Z",
     "shell.execute_reply": "2024-02-02T18:50:53.634661Z",
     "shell.execute_reply.started": "2024-02-02T18:50:53.632594Z"
    },
    "id": "Z2ItflSDFBUC"
   },
   "outputs": [],
   "source": [
    "max_train_batches_per_epoch: int = 100\n",
    "max_test_batches_per_epoch: int = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOXB6EkiFBUC"
   },
   "source": [
    "**Question 2 (Part II ✅ | Part III/MPhil ✅):**\n",
    "\n",
    "(This is meant to be a conceptual question. You should provide written answers for this. **No more than 3 sentences**. **No code** is needed)\n",
    "\n",
    "1. Consider the three following scenarios for a population of five clients and identify how weighing client updates by the number of samples compares to unweighted averaging:\n",
    "  -  Clients have the same number of samples\n",
    "      - Unweighted and weighted return the same results, as the weights are all the same across the population.\n",
    "  -  One client has 50% of the samples, and they are of high quality (e.g., coherent English text)\n",
    "      - The model's training will be dominated by the high-quality training data.\n",
    "  - One client has 50% of the samples, and they are of very low quality (e.g, incomprehensible mashup of letters)\n",
    "      - The model's training will be dominated by the low-quality training data.\n",
    "\n",
    "**Question 3 (Part III/MPhil ✅):**\n",
    "\n",
    "(This is meant to be a conceptual question. You should provide written answers for this. **No more than 3 sentences**. **No code** is needed)\n",
    "1. In the previous three scenarios, what would happen if we set a homogenous number of training steps for all clients instead of epochs? I.e., clients loop over their dataset until the precise moment when they have processed N total samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T17:38:44.192477Z",
     "iopub.status.busy": "2024-01-30T17:38:44.191973Z",
     "iopub.status.idle": "2024-01-30T17:38:44.198576Z",
     "shell.execute_reply": "2024-01-30T17:38:44.197720Z",
     "shell.execute_reply.started": "2024-01-30T17:38:44.192439Z"
    }
   },
   "source": [
    "- Note: I'm a part II student.\n",
    "    - Same number of samples: training will just proceed as usual.\n",
    "    - 50% high quality samples: The datasets with a smaller amount of data will process each data point more, so they will begin to overfit, introducing noise in the training process.\n",
    "    - 50% low quality samples: As the 50% low-quality model now trains less than it used to be, its gradients will have less of an impact on the entire model, meaning that the error it introduces in the model will be decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YYcbCW4FBUC"
   },
   "source": [
    "While FL may use any training function that centralised ML can, there is an extra consideration regarding how much information a client may leak regarding their local dataset. For example, the model may contain enough data to recreate local samples perfectly under the right circumstances unless defensive measures are employed.\n",
    "\n",
    "Later labs and lectures will explore several methods for mitigating such concerns. Until then, the three following pieces of information are currently considered acceptable from a privacy standpoint:\n",
    "1. Model weights.\n",
    "2. The size of the local dataset.\n",
    "3. Cumulative loss values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:53.636430Z",
     "iopub.status.busy": "2024-02-02T18:50:53.636154Z",
     "iopub.status.idle": "2024-02-02T18:50:53.641905Z",
     "shell.execute_reply": "2024-02-02T18:50:53.641382Z",
     "shell.execute_reply.started": "2024-02-02T18:50:53.636406Z"
    },
    "id": "fyX641rBkYiv"
   },
   "outputs": [],
   "source": [
    "def train_FEMNIST(\n",
    "    net: Module,\n",
    "    train_loader: DataLoader,\n",
    "    epochs: int,\n",
    "    device: str,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: Module,\n",
    ") -> float:\n",
    "    \"\"\"Trains the network on the training set.\n",
    "\n",
    "    Args:\n",
    "        net (Module): generic module object describing the network to train.\n",
    "        train_loader (DataLoader): dataloader to iterate during the training.\n",
    "        epochs (int): number of epochs of training.\n",
    "        device (str): device name onto which perform the computation.\n",
    "        optimizer (torch.optim.Optimizer): optimizer object.\n",
    "        criterion (Module): generic module describing the loss function.\n",
    "\n",
    "    Returns:\n",
    "        float: the final epoch mean train loss.\n",
    "    \"\"\"\n",
    "    net.train()\n",
    "    running_loss, total = 0.0, 0\n",
    "    for _ in tqdm(range(epochs)):\n",
    "        running_loss = 0.0\n",
    "        total, batch_cnt = 0, 0\n",
    "        for i, (data, labels) in enumerate(train_loader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "            loss = criterion(net(data), labels)\n",
    "            running_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Break if we have exceeded the upper limit\n",
    "            # On training batches for a given round\n",
    "            # Simulate enumerate counting for train/test parity\n",
    "            if batch_cnt > max_train_batches_per_epoch:\n",
    "                break\n",
    "            batch_cnt += 1\n",
    "    return running_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:53.642969Z",
     "iopub.status.busy": "2024-02-02T18:50:53.642681Z",
     "iopub.status.idle": "2024-02-02T18:50:53.648434Z",
     "shell.execute_reply": "2024-02-02T18:50:53.647769Z",
     "shell.execute_reply.started": "2024-02-02T18:50:53.642941Z"
    },
    "id": "TmFKmWHLkl-Z"
   },
   "outputs": [],
   "source": [
    "def test_FEMNIST(\n",
    "    net: Module,\n",
    "    test_loader: DataLoader,\n",
    "    device: str,\n",
    "    criterion: Module,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Validate the network on a test set.\n",
    "\n",
    "    Args:\n",
    "        net (Module): generic module object describing the network to test.\n",
    "        test_loader (DataLoader): dataloader to iterate during the testing.\n",
    "        device (str):  device name onto which perform the computation.\n",
    "        criterion (Module): generic module describing the loss function.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: couple of average test loss and average accuracy on the test set.\n",
    "    \"\"\"\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (data, labels) in enumerate(\n",
    "            tqdm(test_loader, total=min(max_test_batches_per_epoch, len(test_loader)))\n",
    "        ):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = net(data)\n",
    "\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Break if we have exceed the upper limit\n",
    "            # On testing batches\n",
    "            if i > max_test_batches_per_epoch:\n",
    "                break\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:53.649787Z",
     "iopub.status.busy": "2024-02-02T18:50:53.649500Z",
     "iopub.status.idle": "2024-02-02T18:50:53.654197Z",
     "shell.execute_reply": "2024-02-02T18:50:53.653632Z",
     "shell.execute_reply.started": "2024-02-02T18:50:53.649763Z"
    },
    "id": "LWzf1Z9Q40ia"
   },
   "outputs": [],
   "source": [
    "class CompleteSimpleClient(SimpleClient):\n",
    "    def _load_dataset(self, name, config: Dict[str, Any]) -> Dataset:\n",
    "        full_file: Path = self.partition_dir / self.cid\n",
    "        return load_FEMNIST_dataset(mapping=full_file, name=name)\n",
    "\n",
    "    def _train(\n",
    "        self, net: Module, train_loader: DataLoader, config=Dict[str, Any]\n",
    "    ) -> float:\n",
    "        # Notice the usage of the config dict to obtain training\n",
    "        # parameters for a given client\n",
    "        return train_FEMNIST(\n",
    "            net=net,\n",
    "            train_loader=train_loader,\n",
    "            epochs=config[\"epochs\"],\n",
    "            device=self.device,\n",
    "            optimizer=torch.optim.AdamW(\n",
    "                net.parameters(),\n",
    "                lr=config[\"client_learning_rate\"],\n",
    "                weight_decay=config[\"weight_decay\"],\n",
    "            ),\n",
    "            criterion=torch.nn.CrossEntropyLoss(),\n",
    "        )\n",
    "\n",
    "    def _test(\n",
    "        self, net, test_loader: DataLoader, config: Dict[str, Any]\n",
    "    ) -> Tuple[float, float]:\n",
    "        return test_FEMNIST(\n",
    "            net=net,\n",
    "            test_loader=test_loader,\n",
    "            device=self.device,\n",
    "            criterion=torch.nn.CrossEntropyLoss(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Asc5DtAN5zXu"
   },
   "source": [
    "This client can now encapsulate any partition of the FEMNIST dataset and train and test on it. To put it into action, we shall define a small CNN taken from the [60 minute PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-convolutional-neural-network) and the training/testing configurations used by the fit/evaluate functions of the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:53.656398Z",
     "iopub.status.busy": "2024-02-02T18:50:53.656116Z",
     "iopub.status.idle": "2024-02-02T18:50:53.660644Z",
     "shell.execute_reply": "2024-02-02T18:50:53.660081Z",
     "shell.execute_reply.started": "2024-02-02T18:50:53.656376Z"
    },
    "id": "9khkMcJ142cX"
   },
   "outputs": [],
   "source": [
    "##  Define a simple CNN\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 62)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTGpzOTdFBUC"
   },
   "source": [
    "The following global variables will be set to standardise training and testing across experiments. This means fixing:\n",
    "- The starting initialised model.\n",
    "- Local train/test parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:53.661874Z",
     "iopub.status.busy": "2024-02-02T18:50:53.661629Z",
     "iopub.status.idle": "2024-02-02T18:50:53.687724Z",
     "shell.execute_reply": "2024-02-02T18:50:53.687169Z",
     "shell.execute_reply.started": "2024-02-02T18:50:53.661848Z"
    },
    "id": "wmsbBUGyFBUC"
   },
   "outputs": [],
   "source": [
    "# All experiments will have the same initialisation.\n",
    "# All differences in performance will come from training\n",
    "def get_network_generator():\n",
    "    untrained_net: Net = Net()\n",
    "\n",
    "    def generated_net():\n",
    "        return deepcopy(untrained_net)\n",
    "\n",
    "    return generated_net\n",
    "\n",
    "\n",
    "network_generator = get_network_generator()\n",
    "\n",
    "centralized_train_config: Dict[str, Any] = {\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"client_learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"num_workers\": 0,\n",
    "}\n",
    "\n",
    "test_config: Dict[str, Any] = {\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:53.688795Z",
     "iopub.status.busy": "2024-02-02T18:50:53.688506Z",
     "iopub.status.idle": "2024-02-02T18:50:54.402168Z",
     "shell.execute_reply": "2024-02-02T18:50:54.401407Z",
     "shell.execute_reply.started": "2024-02-02T18:50:53.688770Z"
    },
    "id": "0cV3STZ16vYx"
   },
   "outputs": [],
   "source": [
    "# Instantiate the centralised client and model\n",
    "centralized_client = CompleteSimpleClient(cid=0, partition_dir=centralized_partition)\n",
    "centralized_net = network_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:50:54.403571Z",
     "iopub.status.busy": "2024-02-02T18:50:54.403192Z",
     "iopub.status.idle": "2024-02-02T18:51:04.919547Z",
     "shell.execute_reply": "2024-02-02T18:51:04.919006Z",
     "shell.execute_reply.started": "2024-02-02T18:50:54.403540Z"
    },
    "id": "UOEKuiCQ6KVR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:09<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20189, {}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the centralised model\n",
    "centralized_net, *rest = fit_client_seeded(\n",
    "    centralized_client, params=centralized_net, conf=centralized_train_config\n",
    ")\n",
    "print(rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T18:51:04.920478Z",
     "iopub.status.busy": "2024-02-02T18:51:04.920218Z",
     "iopub.status.idle": "2024-02-02T18:51:06.119465Z",
     "shell.execute_reply": "2024-02-02T18:51:06.118966Z",
     "shell.execute_reply.started": "2024-02-02T18:51:04.920461Z"
    },
    "id": "Jj4rAKSx6s8q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:01, 87.11it/s]                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(377.96734952926636, 2329, {'local_accuracy': 0.046262254901960786})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the trained centralised model\n",
    "result = centralized_client.evaluate(net=centralized_net, config=test_config)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INODwg_gVyY2"
   },
   "source": [
    "**Question 4 (Part II ✅ | Part III/MPhil ✅):**\n",
    "\n",
    "(This is meant to be a conceptual question. You should provide written answers for this. **No more than 3 sentences**. **No code** is needed)\n",
    "\n",
    "1. Read about [data-parallelism](https://d2l.ai/chapter_computational-performance/multiple-gpus.html), if we were to train the centralized model in a data-parallel fashion how often would we need to communicate between the model replicas?\n",
    "    - Whenever a training step is completed on a GPU it needs to write back the loss and the gradients to the central model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RxdrTSpuXEE"
   },
   "source": [
    "# END OF PART I:\n",
    "\n",
    "Continue to the part 2 notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uE4qbA0rQN69"
   },
   "source": [
    "(c) 2024 Alexandru-Andrei Iacob, Lorenzo Sani"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "224d0ab12de28608c5a4d7a39646ed9b98595177ad290f2912bfa68781d77d65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
